{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('json/2019_pass_or_fail.json', encoding='UTF8') as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 데이터를 pandas DataFrame으로 변환\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# \"최저 지원 유무\" 열 삭제\n",
    "df_modify = df.drop(columns=['최저적용유무', '최초지원결과'])\n",
    "\n",
    "# 빈 값이 있는 행 제거\n",
    "df_modify = df_modify.replace('', pd.NA).dropna()\n",
    "\n",
    "# 결과를 다시 JSON 형식으로 변환\n",
    "modified_data = df_modify.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_to_int(value, range_start=1, range_end=500):\n",
    "    hashed_value = hash(value)\n",
    "    mapped_value = (hashed_value % (range_end - range_start + 1)) + range_start\n",
    "    return mapped_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자로 변환하여 NumPy 배열 생성\n",
    "numeric_data = np.array([\n",
    "    [\n",
    "        data['전과목(평균)'],\n",
    "        data['국영수사(평균)'],\n",
    "        data['국영수과(평균)'],\n",
    "        data['국영수탐(백분위)'],\n",
    "        data['국영수탐(등급)']\n",
    "    ] \n",
    "    for data in modified_data\n",
    "])\n",
    "\n",
    "# 문자열 데이터를 numpy 배열로 변환 (hashing trick 적용) --> 수정 필요\n",
    "string_data = np.array([\n",
    "    [\n",
    "        hash_to_int(data['지역']),\n",
    "        hash_to_int(data['계열']),\n",
    "        hash_to_int(data['대학명']),\n",
    "        hash_to_int(data['학과명']),\n",
    "        hash_to_int(data['전형유형']),\n",
    "        hash_to_int(data['전형명'])\n",
    "    ]\n",
    "    for data in modified_data\n",
    "])\n",
    "\n",
    "# 결과값을 정수로 매핑 (\"최종지원결과\"를 1 또는 0으로 변환)\n",
    "result = np.array([data['최종지원결과'] for data in modified_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.32' '1.31' '1.22' '252.5' '2.67']\n",
      " ['1.47' '1.51' '1.29' '281.5' '1.67']\n",
      " ['1.3' '1.3' '1.3' '225.5' '3.67']\n",
      " ['1.39' '1.44' '1.33' '224' '3.33']\n",
      " ['1.59' '1.41' '1.36' '263.5' '2.17']]\n",
      "[[341 497  78 160 416 273]\n",
      " [341 497  78 160 416 273]\n",
      " [341 497  78 160 416 273]\n",
      " [341 497  78 160 416 273]\n",
      " [341 497  78 160 416 273]]\n",
      "['합' '합' '합' '합' '불']\n"
     ]
    }
   ],
   "source": [
    "print(numeric_data[0:5])\n",
    "print(string_data[0:5])\n",
    "print(result[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.32   1.31   1.22 252.5    2.67]\n",
      " [  1.47   1.51   1.29 281.5    1.67]]\n",
      "[[341 497  78 160 416 273]\n",
      " [341 497  78 160 416 273]]\n",
      "[[341.   497.    78.   160.   416.   273.     1.32   1.31   1.22 252.5\n",
      "    2.67]\n",
      " [341.   497.    78.   160.   416.   273.     1.47   1.51   1.29 281.5\n",
      "    1.67]]\n",
      "[[341.   497.    78.   160.   416.   273.     1.32   1.31   1.22 252.5\n",
      "    2.67]\n",
      " [341.   497.    78.   160.   416.   273.     1.47   1.51   1.29 281.5\n",
      "    1.67]]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "# 두 데이터를 수평으로 결합\n",
    "numeric_data = np.array(numeric_data).astype(float)\n",
    "\n",
    "print(numeric_data[0:2])\n",
    "print(string_data[0:2])\n",
    "\n",
    "# 두 배열을 수평으로 결합\n",
    "combined_data = np.concatenate((string_data, numeric_data), axis=1, )\n",
    "combined_data = np.array(combined_data, dtype=np.float64)\n",
    "print(combined_data[0:2])\n",
    "\n",
    "# 2차원 배열의 각 행에 대해 문자열을 정수로 변환\n",
    "X = np.array(combined_data).astype(float)\n",
    "\n",
    "# y값 문자열에 대해 원-핫 인코딩\n",
    "y = np.array(result)\n",
    "e = LabelEncoder()\n",
    "e.fit(y)\n",
    "Y = e.transform(y)\n",
    "\n",
    "print(X[0:2])\n",
    "print(Y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "816/816 [==============================] - 2s 1ms/step - loss: 0.7958 - accuracy: 0.8330\n",
      "Epoch 2/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.8571\n",
      "Epoch 3/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3813 - accuracy: 0.8591\n",
      "Epoch 4/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3747 - accuracy: 0.8584\n",
      "Epoch 5/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3715 - accuracy: 0.8576\n",
      "Epoch 6/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3698 - accuracy: 0.8575\n",
      "Epoch 7/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3687 - accuracy: 0.8579\n",
      "Epoch 8/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3703 - accuracy: 0.8574\n",
      "Epoch 9/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3656 - accuracy: 0.8585\n",
      "Epoch 10/100\n",
      "816/816 [==============================] - 1s 994us/step - loss: 0.3659 - accuracy: 0.8581\n",
      "Epoch 11/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3647 - accuracy: 0.8585\n",
      "Epoch 12/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3652 - accuracy: 0.8586\n",
      "Epoch 13/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3631 - accuracy: 0.8592\n",
      "Epoch 14/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3634 - accuracy: 0.8588\n",
      "Epoch 15/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3623 - accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3610 - accuracy: 0.8595\n",
      "Epoch 17/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3601 - accuracy: 0.8593\n",
      "Epoch 18/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3605 - accuracy: 0.8594\n",
      "Epoch 19/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3599 - accuracy: 0.8596\n",
      "Epoch 20/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3584 - accuracy: 0.8596\n",
      "Epoch 21/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3587 - accuracy: 0.8592\n",
      "Epoch 22/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3573 - accuracy: 0.8593\n",
      "Epoch 23/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3573 - accuracy: 0.8601\n",
      "Epoch 24/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3554 - accuracy: 0.8596\n",
      "Epoch 25/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3561 - accuracy: 0.8595\n",
      "Epoch 26/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3534 - accuracy: 0.8589\n",
      "Epoch 27/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3532 - accuracy: 0.8593\n",
      "Epoch 28/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3534 - accuracy: 0.8598\n",
      "Epoch 29/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3517 - accuracy: 0.8597\n",
      "Epoch 30/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8601\n",
      "Epoch 31/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.8598\n",
      "Epoch 32/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3515 - accuracy: 0.8597\n",
      "Epoch 33/100\n",
      "816/816 [==============================] - 1s 980us/step - loss: 0.3504 - accuracy: 0.8601\n",
      "Epoch 34/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3501 - accuracy: 0.8602\n",
      "Epoch 35/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3495 - accuracy: 0.8606\n",
      "Epoch 36/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3484 - accuracy: 0.8605\n",
      "Epoch 37/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8607\n",
      "Epoch 38/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3478 - accuracy: 0.8606\n",
      "Epoch 39/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3474 - accuracy: 0.8609\n",
      "Epoch 40/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3471 - accuracy: 0.8607\n",
      "Epoch 41/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3467 - accuracy: 0.8607\n",
      "Epoch 42/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3463 - accuracy: 0.8609\n",
      "Epoch 43/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3468 - accuracy: 0.8606\n",
      "Epoch 44/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3465 - accuracy: 0.8604\n",
      "Epoch 45/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3461 - accuracy: 0.8604\n",
      "Epoch 46/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3454 - accuracy: 0.8608\n",
      "Epoch 47/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8604\n",
      "Epoch 48/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3460 - accuracy: 0.8606\n",
      "Epoch 49/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3449 - accuracy: 0.8608\n",
      "Epoch 50/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3457 - accuracy: 0.8608\n",
      "Epoch 51/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3448 - accuracy: 0.8607\n",
      "Epoch 52/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3450 - accuracy: 0.8609\n",
      "Epoch 53/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3444 - accuracy: 0.8603\n",
      "Epoch 54/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3444 - accuracy: 0.8605\n",
      "Epoch 55/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3445 - accuracy: 0.8603\n",
      "Epoch 56/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.8604\n",
      "Epoch 57/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3438 - accuracy: 0.8606\n",
      "Epoch 58/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3443 - accuracy: 0.8608\n",
      "Epoch 59/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3437 - accuracy: 0.8611\n",
      "Epoch 60/100\n",
      "816/816 [==============================] - 1s 998us/step - loss: 0.3441 - accuracy: 0.8607\n",
      "Epoch 61/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3434 - accuracy: 0.8610\n",
      "Epoch 62/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8610\n",
      "Epoch 63/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3431 - accuracy: 0.8608\n",
      "Epoch 64/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3433 - accuracy: 0.8606\n",
      "Epoch 65/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8607\n",
      "Epoch 66/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3433 - accuracy: 0.8609\n",
      "Epoch 67/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.8608\n",
      "Epoch 68/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.8610\n",
      "Epoch 69/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3424 - accuracy: 0.8613\n",
      "Epoch 70/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8610\n",
      "Epoch 71/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8609\n",
      "Epoch 72/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3419 - accuracy: 0.8611\n",
      "Epoch 73/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8609\n",
      "Epoch 74/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3421 - accuracy: 0.8608\n",
      "Epoch 75/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8612\n",
      "Epoch 76/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3420 - accuracy: 0.8612\n",
      "Epoch 77/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3416 - accuracy: 0.8606\n",
      "Epoch 78/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3407 - accuracy: 0.8611\n",
      "Epoch 80/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3408 - accuracy: 0.8613\n",
      "Epoch 81/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3410 - accuracy: 0.8610\n",
      "Epoch 82/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8611\n",
      "Epoch 83/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8610\n",
      "Epoch 84/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3403 - accuracy: 0.8612\n",
      "Epoch 85/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3413 - accuracy: 0.8612\n",
      "Epoch 86/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3406 - accuracy: 0.8612\n",
      "Epoch 87/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3400 - accuracy: 0.8615\n",
      "Epoch 88/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8609\n",
      "Epoch 89/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8613\n",
      "Epoch 90/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3398 - accuracy: 0.8615\n",
      "Epoch 91/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3396 - accuracy: 0.8615\n",
      "Epoch 92/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3397 - accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3396 - accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3389 - accuracy: 0.8614\n",
      "Epoch 95/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3392 - accuracy: 0.8611\n",
      "Epoch 96/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3389 - accuracy: 0.8608\n",
      "Epoch 97/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3391 - accuracy: 0.8615\n",
      "Epoch 98/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3390 - accuracy: 0.8612\n",
      "Epoch 99/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3395 - accuracy: 0.8609\n",
      "Epoch 100/100\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8614\n",
      "816/816 [==============================] - 1s 1ms/step - loss: 0.3399 - accuracy: 0.8583\n",
      "Test Accuracy:  0.8583301305770874\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=11, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# 마지막 레이어는 예측결과(sigmoid -> 0~1확률)\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(np.array(X_train), np.array(Y_train), epochs=100, batch_size=128, validation_batch_size=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  accuracy\n",
      "0   0.795819  0.832963\n",
      "1   0.398440  0.857131\n",
      "2   0.381335  0.859084\n",
      "3   0.374712  0.858433\n",
      "4   0.371464  0.857561\n",
      "..       ...       ...\n",
      "95  0.338948  0.860798\n",
      "96  0.339116  0.861468\n",
      "97  0.339009  0.861152\n",
      "98  0.339504  0.860874\n",
      "99  0.338643  0.861401\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "print(hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\강민지\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\university_predict\\string_number_test.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/university_predict/string_number_test.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hist_df\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/university_predict/string_number_test.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 테스트셋 오차\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitHub/university_predict/string_number_test.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_vloss \u001b[39m=\u001b[39m hist_df[\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/university_predict/string_number_test.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# 학습셋 오차\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/university_predict/string_number_test.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_loss \u001b[39m=\u001b[39m hist_df[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\강민지\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\강민지\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    }
   ],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df\n",
    "\n",
    "# 테스트셋 오차\n",
    "y_vloss = hist_df['val_loss']\n",
    "# 학습셋 오차\n",
    "y_loss = hist_df['loss']\n",
    "\n",
    "# 테스트셋 오차 -> 빨간색, 학습셋 오차 -> 파란색\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label=\"Testset_loss\")\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label=\"Trainset_loss\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
